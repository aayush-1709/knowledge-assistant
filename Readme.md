# ğŸ“„ Knowledgeâ€‘Base Assistant
# Insight AI

A **localâ€‘first Retrievalâ€‘Augmented Generation (RAG) chatbot** that lets you ask naturalâ€‘language questions about any set of documents.
It combines fast **MiniLM sentence embeddings**, a **persistent Chroma vector store**, and **GoogleÂ Gemini** to craft concise answers, all wrapped in a Streamlit UI and a simple CLI.

---

## ğŸ—ï¸ TechÂ Stack

* **PythonÂ 3.9Â +**
* **LlamaIndex** - indexing, retrieval, RAG utilities
* **ChromaDB** â€“ local vector database
* **Sentenceâ€‘Transformers** (`allâ€‘MiniLMâ€‘L6â€‘v2`) â€“ embeddings
* **GoogleÂ Gemini** via `llama-index-llms-google-genai`
* **Streamlit** â€“ web UI

---

## ğŸ“‚ Project Layout

```
.
â”œâ”€â”€ app.py            # Streamlit UI
â”œâ”€â”€ query.py          # Commandâ€‘line Q&A
â”œâ”€â”€ ingest.py         # One command doc ingestion
â”œâ”€â”€ docs/             # â† put your source documents here
â”œâ”€â”€ data/
â”‚   â””â”€â”€ chroma/       # autoâ€‘generated Chroma files (vectors + metadata)
â”œâ”€â”€ .env              # holds GOOGLE_API_KEY
â””â”€â”€ requirements.txt  # pip dependencies
```

---

## ğŸš€ QuickÂ Start

1. **Clone & set up env**

   ```
   git clone https://github.com/aayush-1709/knowledge-assistant
   python -m venv .venv && source .venv/bin/activate
   pip install -r requirements.txt
   ```

2. **Add your Gemini key**

   ```bash
    GEMINI_API_KEY="your-key" (Create through https://aistudio.google.com/)
   ```

3. **Ingest documents**

   ```bash
   # copy your PDFs, TXTs, etc. into ./docs first
   python ingest.py
   ```

4. **Ask questions**

   * **CLI**

     ```bash
     python query.py
     ```
   * **Streamlit UI**

     ```bash
     streamlit run app.py
     ```

---

## ğŸ™ Acknowledgements
* [LlamaIndex](https://github.com/run-llama/llama_index) community for the RAG framework.
* [GoogleÂ AIÂ Studio](https://ai.google.dev/) for access to Gemini.
